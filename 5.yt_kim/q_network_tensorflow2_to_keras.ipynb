{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_network_tensorflow2_to_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lI3lDV7Zj2mH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#16*16의 단위행렬 생성.\n",
        "# [x:x+1]로 한 경우 결과적으로 범위는 x\n",
        "def one_hot(x):\n",
        "    return np.identity(16)[x:x+1].astype(np.float32)"
      ],
      "metadata": {
        "id": "j3Lauf3RkmV1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "# Set Q-learning parameters\n",
        "num_episodes = 2000\n",
        "learning_rate = 0.1\n",
        "dis = .99\n",
        "\n",
        "# Input and output size based on the Env\n",
        "input_size = env.observation_space.n\n",
        "output_size = env.action_space.n\n",
        "\n",
        "# weight 기존코드\n",
        "# W = tf.Variable(tf.random.uniform([input_size, output_size], 0, 0.01), dtype=tf.float32)\n",
        "\n",
        "# from keras import backend as K로 정의. 기존 코드와 비교했을 때 상당히 유사함\n",
        "W = K.variable(K.random_uniform_variable(shape = (input_size, output_size), low = 0, high = 0.1), dtype= \"float32\")\n",
        "\n",
        "# 기존코드 - 케라스코드에서 차이가 거의 없음\n",
        "# optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
        "optimizer = keras.optimizers.SGD(lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuM3M_oWk_8C",
        "outputId": "96f0170b-7a0d-4cc2-c57a-0e363d63c8fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "# rewards per episode\n",
        "rList = []\n",
        "for i in range(num_episodes):\n",
        "    # Reset environment and get first new observation\n",
        "    state = env.reset()\n",
        "    rAll = 0\n",
        "    done = False\n",
        "    local_loss = []\n",
        "\n",
        "    e = 1. / ((i / 50) + 10)\n",
        "    # The Q-Table learning algorithm\n",
        "    while not done:\n",
        "        # Choose an action by greedly (with a chance of random action)\n",
        "        # from the Q-network\n",
        "        # q_value = np.matmul(one_hot(state), W)\n",
        "        # 위에 적어둔 코드는 작동하지 않음. 찾아보니 tf.matmul은 3차원 이상의 텐서도 계산가능하다고함\n",
        "        # 넘파이 matmul은 텐서플로우 matmul과 달리 작동하지 않는 것으로 추정\n",
        "        # 이에 대한 해답을 주는 자료는 찾을 수 없음\n",
        "        q_value = tf.matmul(one_hot(state), W)\n",
        "        q_value = np.array(q_value.numpy())\n",
        "\n",
        "        # e greedy\n",
        "        if np.random.rand(1) < e:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(q_value)\n",
        "\n",
        "        # Get new state and reward from environment\n",
        "        state_next, reward, done, _ = env.step(action)\n",
        "        if done:\n",
        "            # Update Q, and no q_value+1, since it's action termial state\n",
        "            q_value[0, action] = reward\n",
        "        else:\n",
        "            # Obtain the Q_s` values by feeding the new state through our network\n",
        "            q_score_next = np.matmul(one_hot(state_next), W)\n",
        "            # Update Q\n",
        "            q_value[0, action] = reward + dis * np.max(q_score_next)\n",
        "\n",
        "        # K.sum(input_value)\n",
        "        # loss = lambda: K.sum(K.square(q_value - np.matmul(one_hot(state), W)))\n",
        "        # 위의 loss를 구하는 것은 당장은 작동이 되나 밑의 optimizer.minimize 부분에서 막힘\n",
        "        # reduce_sum과 sum의 기능이 거의 유사함에도 작동이 되지 않은 것으로 볼 때\n",
        "        # reduce_sum과 sum에는 분명한 차이가 있는 것으로 보임.\n",
        "        # tf.matmul과 np.matmul 을 돌렸을 때 실행은 가능하지만\n",
        "        # 해당 셀 16번째 줄부터 tf.matmul에 대한 이유로 tf.matmul을 사용하는 것이 바람직한 것 같음\n",
        "        loss = lambda: tf.reduce_sum(input_tensor=tf.square(q_value - tf.matmul(one_hot(state), W)))\n",
        "\n",
        "        # optimizer, loss will be updated to lower\n",
        "        # 처음 이 부분에서 오류가 났을 때 두 개의 인자를 하나씩 빼 보았지만 실행되지 않았음\n",
        "        optimizer.minimize(loss, var_list = W)\n",
        "\n",
        "        rAll += reward\n",
        "        state = state_next\n",
        "    rList.append(rAll)"
      ],
      "metadata": {
        "id": "stdXawdu47HF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{(time.time() - start_time)} seconds')\n",
        "print(\"Success rate: \" + str(sum(rList) / num_episodes))\n",
        "plt.bar(range(len(rList)), rList, color='b', alpha=0.4)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "ez2-Ibhg-4Yd",
        "outputId": "94bf889b-5da2-43df-8733-7ba7d74f07e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "305.7996985912323 seconds\n",
            "Success rate: 0.456\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPo0lEQVR4nO3df6zdd13H8eeLlmECA4a9kqXtaNFCbNS4eTOX8EMSELpFWxVC2ogMnDQm1EBATcnMJPOvQcSEOMEaFn4EGANFb2JJQZySGDt3B2OsG2V3ZbjWsZUxwQRlVN/+cb7F07t77jmnPefc9ePzkZzc7/fz/Zzv930+33Ne/d7v955vU1VIks5/T1nrAiRJk2GgS1IjDHRJaoSBLkmNMNAlqRHr12rDGzZsqC1btqzV5iXpvHTHHXd8q6rmVlq2ZoG+ZcsWFhcX12rzknReSvKNQcs85SJJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaMTTQk9yU5JEkdw9YniTvTbKU5K4kl02+TEnSMKMcoX8Q2LHK8iuBbd1jL/C+cy9LkjSuoYFeVV8Avr1Kl13Ah6vnMPDsJBdPqkBJ0mgmcQ59I/Bg3/zxru0JkuxNsphk8eTJkxPY9HgOHBjctvznas9bqc+oz1mtfVAt/c8ZVF//80fd/jivY5Q6B9UySo0rPWeUdY76WkYdn+Xzg17bOOO5vP+gMVxtnYP6D6tpWG2DXuswq72GcWtZ6Xmj1DbK/hj1fTXuZ2G1540yBtMy04uiVXWgquaran5ubsVbEUiSztIkAv0EsLlvflPXJkmaoUkE+gLw+u6vXa4AvlNVD01gvZKkMQy922KSjwMvAzYkOQ78IfBUgKp6P3AQuApYAr4HvHFaxUqSBhsa6FW1Z8jyAt48sYokSWfFb4pKUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGjFSoCfZkeRokqUk+1dYfkmSW5N8KcldSa6afKmSpNUMDfQk64AbgSuB7cCeJNuXdfsD4JaquhTYDfzZpAuVJK1ulCP0y4GlqjpWVY8DNwO7lvUp4Jnd9LOAf5tciZKkUYwS6BuBB/vmj3dt/d4JvC7JceAg8DsrrSjJ3iSLSRZPnjx5FuVKkgaZ1EXRPcAHq2oTcBXwkSRPWHdVHaiq+aqan5ubm9CmJUkwWqCfADb3zW/q2vpdA9wCUFX/DPwIsGESBUqSRjNKoN8ObEuyNckF9C56Lizr86/AywGS/CS9QPeciiTN0NBAr6pTwD7gEHAvvb9mOZLk+iQ7u25vB96U5MvAx4E3VFVNq2hJ0hOtH6VTVR2kd7Gzv+26vul7gBdNtjRJ0jj8pqgkNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpESMFepIdSY4mWUqyf0Cf1ya5J8mRJB+bbJmSpGHWD+uQZB1wI/CLwHHg9iQLVXVPX59twDuAF1XVY0l+bFoFS5JWNsoR+uXAUlUdq6rHgZuBXcv6vAm4saoeA6iqRyZbpiRpmFECfSPwYN/88a6t3wuAFyT5pySHk+yYVIGSpNEMPeUyxnq2AS8DNgFfSPLTVfXv/Z2S7AX2AlxyySUT2rQkCUY7Qj8BbO6b39S19TsOLFTVD6rq68DX6AX8GarqQFXNV9X83Nzc2dYsSVrBKIF+O7AtydYkFwC7gYVlff6a3tE5STbQOwVzbIJ1SpKGGBroVXUK2AccAu4FbqmqI0muT7Kz63YIeDTJPcCtwO9V1aPTKlqS9EQjnUOvqoPAwWVt1/VNF/C27iFJWgN+U1SSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxUqAn2ZHkaJKlJPtX6ffqJJVkfnIlSpJGMTTQk6wDbgSuBLYDe5JsX6HfhcBbgNsmXaQkabhRjtAvB5aq6lhVPQ7cDOxaod8fATcA/zXB+iRJIxol0DcCD/bNH+/afijJZcDmqvrb1VaUZG+SxSSLJ0+eHLtYSdJg53xRNMlTgPcAbx/Wt6oOVNV8Vc3Pzc2d66YlSX1GCfQTwOa++U1d22kXAj8F/EOSB4ArgAUvjErSbI0S6LcD25JsTXIBsBtYOL2wqr5TVRuqaktVbQEOAzuranEqFUuSVjQ00KvqFLAPOATcC9xSVUeSXJ9k57QLlCSNZv0onarqIHBwWdt1A/q+7NzLkiSNy2+KSlIjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxUqAn2ZHkaJKlJPtXWP62JPckuSvJ55M8b/KlSpJWMzTQk6wDbgSuBLYDe5JsX9btS8B8Vf0M8CngXZMuVJK0ulGO0C8HlqrqWFU9DtwM7OrvUFW3VtX3utnDwKbJlilJGmaUQN8IPNg3f7xrG+Qa4DMrLUiyN8liksWTJ0+OXqUkaaiJXhRN8jpgHnj3Ssur6kBVzVfV/Nzc3CQ3LUn/760foc8JYHPf/Kau7QxJXgFcC/xCVX1/MuVJkkY1yhH67cC2JFuTXADsBhb6OyS5FPhzYGdVPTL5MiVJwwwN9Ko6BewDDgH3ArdU1ZEk1yfZ2XV7N/AM4JNJ7kyyMGB1kqQpGeWUC1V1EDi4rO26vulXTLguSdKY/KaoJDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1YqRAT7IjydEkS0n2r7D8aUk+0S2/LcmWSRcqSVrd0EBPsg64EbgS2A7sSbJ9WbdrgMeq6ieAPwFumHShkqTVjXKEfjmwVFXHqupx4GZg17I+u4APddOfAl6eJJMrU5I0TKpq9Q7Ja4AdVfVb3fxvAD9fVfv6+tzd9Tnezd/f9fnWsnXtBfZ2sy8Ejp5l3RuAbw3tNXvWNb4na23WNR7rGs+51PW8qppbacH6s69nfFV1ADhwrutJslhV8xMoaaKsa3xP1tqsazzWNZ5p1TXKKZcTwOa++U1d24p9kqwHngU8OokCJUmjGSXQbwe2Jdma5AJgN7CwrM8CcHU3/Rrg72vYuRxJ0kQNPeVSVaeS7AMOAeuAm6rqSJLrgcWqWgA+AHwkyRLwbXqhP03nfNpmSqxrfE/W2qxrPNY1nqnUNfSiqCTp/OA3RSWpEQa6JDXivAv0YbchmPK2Nye5Nck9SY4keUvX/s4kJ5Lc2T2u6nvOO7pajyZ51RRreyDJV7rtL3Ztz0nyuST3dT8v6tqT5L1dXXcluWxKNb2wb0zuTPLdJG9di/FKclOSR7rvTJxuG3t8klzd9b8vydUrbWsCdb07yVe7bX86ybO79i1J/rNv3N7f95yf6/b/Ulf7OX2xb0BdY++3SX9eB9T1ib6aHkhyZ9c+y/EalA2zfY9V1XnzoHdR9n7g+cAFwJeB7TPc/sXAZd30hcDX6N0O4Z3A767Qf3tX49OArV3t66ZU2wPAhmVt7wL2d9P7gRu66auAzwABrgBum9G++ybwvLUYL+ClwGXA3Wc7PsBzgGPdz4u66YumUNcrgfXd9A19dW3p77dsPf/S1Zqu9iunUNdY+20an9eV6lq2/I+B69ZgvAZlw0zfY+fbEfootyGYmqp6qKq+2E3/B3AvsHGVp+wCbq6q71fV14Eleq9hVvpvyfAh4Ff62j9cPYeBZye5eMq1vBy4v6q+sUqfqY1XVX2B3l9gLd/eOOPzKuBzVfXtqnoM+BywY9J1VdVnq+pUN3uY3nc/Bupqe2ZVHa5eKny477VMrK5VDNpvE/+8rlZXd5T9WuDjq61jSuM1KBtm+h473wJ9I/Bg3/xxVg/UqUnvjpKXArd1Tfu6X51uOv1rFbOtt4DPJrkjvVssADy3qh7qpr8JPHcN6jptN2d+0NZ6vGD88VmLcftNekdyp21N8qUk/5jkJV3bxq6WWdQ1zn6b9Xi9BHi4qu7ra5v5eC3Lhpm+x863QH9SSPIM4C+Bt1bVd4H3AT8O/CzwEL1f+2btxVV1Gb27Yr45yUv7F3ZHImvyN6rpfSFtJ/DJrunJMF5nWMvxGSTJtcAp4KNd00PAJVV1KfA24GNJnjnDkp50+22ZPZx50DDz8VohG35oFu+x8y3QR7kNwVQleSq9HfbRqvorgKp6uKr+u6r+B/gL/u80wczqraoT3c9HgE93NTx8+lRK9/ORWdfVuRL4YlU93NW45uPVGXd8ZlZfkjcAvwT8ehcEdKc0Hu2m76B3fvoFXQ39p2WmUtdZ7LdZjtd64NeAT/TVO9PxWikbmPF77HwL9FFuQzA13Tm6DwD3VtV7+tr7zz//KnD6CvwCsDu9/wBkK7CN3sWYSdf19CQXnp6md1Htbs68JcPVwN/01fX67kr7FcB3+n4tnIYzjpzWerz6jDs+h4BXJrmoO93wyq5topLsAH4f2FlV3+trn0vv/ycgyfPpjc+xrrbvJrmie4++vu+1TLKucffbLD+vrwC+Wt0dX7t6ZzZeg7KBWb/HzuXK7lo86F0d/hq9f22vnfG2X0zvV6a7gDu7x1XAR4CvdO0LwMV9z7m2q/Uo53glfZW6nk/vLwi+DBw5PS7AjwKfB+4D/g54Ttceev9pyf1d3fNTHLOn07tR27P62mY+XvT+QXkI+AG985LXnM340DunvdQ93jilupbonUc9/R57f9f31d3+vRP4IvDLfeuZpxew9wN/Svct8AnXNfZ+m/TndaW6uvYPAr+9rO8sx2tQNsz0PeZX/yWpEefbKRdJ0gAGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWrE/wLdIUDCP2XpbwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XrZyWCgcEj5C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}