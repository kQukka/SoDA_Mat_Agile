{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qlearning_정리 .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FKTxolnpLs6e",
        "dkRhuhdQLzzg",
        "rzmEzeYUL177",
        "hype9rZLMGdJ",
        "Jao_9XHmMOCn",
        "g90vvrhbMaDw",
        "FI_2FiBXMmkM",
        "bkF2c3JmM0oy",
        "BSRY_JyvM7Hi",
        "dWsdswheNEqU"
      ],
      "authorship_tag": "ABX9TyPSl4Zd9MrldoNApqq7uzOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kQukka/SoDA_Mat_Agile/blob/main/5.yt_kim/qlearning_%EC%A0%95%EB%A6%AC_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모듈"
      ],
      "metadata": {
        "id": "FKTxolnpLs6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#코랩은 gym버전이 낮아서 업그레이드 해야 reset 에러가 발생하지 않음\n",
        "!pip install --upgrade gym"
      ],
      "metadata": {
        "id": "YqjZsQFIZbBm",
        "outputId": "466b6329-8a9a-497b-d8cc-ab5b72ee10dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from gym) (4.11.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym) (0.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQg2LHX_Llw7",
        "outputId": "2a3fd95d-a63a-4759-9e2d-d58447b3bc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random as pr\n",
        "\n",
        "from contextlib import closing\n",
        "from io import StringIO\n",
        "import os\n",
        "from os import path\n",
        "from typing import Optional\n",
        "\n",
        "import pygame\n",
        "from pygame.constants import SRCALPHA\n",
        "\n",
        "import gym\n",
        "from gym import Env, spaces, utils\n",
        "#from gym.envs.toy_text.utils import categorical_sample\n",
        "from gym.envs.registration import register"
      ],
      "metadata": {
        "id": "ktL4aZWDLpUK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical_sample 모듈 임포트 에러\n",
        "# 링크 : https://github.com/openai/gym/blob/master/gym/envs/toy_text/utils.py\n",
        "def categorical_sample(prob_n, np_random):\n",
        "    \"\"\"\n",
        "    Sample from categorical distribution\n",
        "    Each row specifies class probabilities\n",
        "    \"\"\"\n",
        "    # np.asarray는 array를 복사할 때 사용한다.\n",
        "    # 무조건 복사하지는 않고 데이터의 형태가 다를 경우에만 복사한다\n",
        "    # 참고 : https://supermemi.tistory.com/66\n",
        "    prob_n = np.asarray(prob_n)\n",
        "\n",
        "    #누적합을 구할 때 np.cumsum을 사용\n",
        "    csprob_n = np.cumsum(prob_n)\n",
        "    return (csprob_n > np_random.random()).argmax()"
      ],
      "metadata": {
        "id": "18aaGIuKLslQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#기본설정값"
      ],
      "metadata": {
        "id": "dkRhuhdQLzzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#common.setting.py\n",
        "NUM_EPISODES = 200000\n",
        "NUM_ROW = 10\n",
        "NUM_COL = 9\n",
        "\n",
        "POINT_ITEM = {'A': (5, 0), 'B': (4, 0), 'C': (3, 0), 'D': (2, 0),\n",
        "              'E': (0, 0), 'F': (0, 1), 'G': (0, 2), 'H': (0, 3), 'I': (0, 4),\n",
        "              'J': (0, 5), 'K': (0, 6), 'L': (0, 7), 'M': (0, 8),\n",
        "              'N': (2, 8), 'O': (3, 8), 'P': (4, 8), 'Q': (5, 8)}\n",
        "\n",
        "POINT_START = (9, 4)\n",
        "POINT_END = (9, 4)\n",
        "\n",
        "POINT_WALL = [(3, 2), (3, 4), (3, 6),\n",
        "              (4, 2), (4, 4), (4, 6),\n",
        "              (5, 2), (5, 4), (5, 6),\n",
        "              (6, 2), (6, 4), (6, 6),\n",
        "              (9, 0), (9, 1), (9, 2), (9, 3),\n",
        "              (9, 5), (9, 6), (9, 7), (9, 8)]\n",
        "\n",
        "#logstic_env.common.py\n",
        "IDX_ACTION_LEFT = 0\n",
        "IDX_ACTION_DOWN = 1\n",
        "IDX_ACTION_RIGHT = 2\n",
        "IDX_ACTION_UP = 3\n",
        "IDX_ACTION = [IDX_ACTION_LEFT, IDX_ACTION_DOWN, IDX_ACTION_RIGHT, IDX_ACTION_UP]\n",
        "\n",
        "INITIAL_ACTION_UP = 'U'\n",
        "INITIAL_ACTION_DOWN = 'D'\n",
        "INITIAL_ACTION_RIGHT = 'R'\n",
        "INITIAL_ACTION_LEFT = 'L'\n",
        "INITIAL_ACTION = [INITIAL_ACTION_LEFT, INITIAL_ACTION_DOWN, INITIAL_ACTION_RIGHT, INITIAL_ACTION_UP]\n",
        "\n",
        "STR_ACTION_UP = 'Up'\n",
        "STR_ACTION_DOWN = 'Down'\n",
        "STR_ACTION_RIGHT = 'Right'\n",
        "STR_ACTION_LEFT = 'Left'\n",
        "STR_ACTION = [STR_ACTION_UP, STR_ACTION_DOWN, STR_ACTION_RIGHT, STR_ACTION_LEFT]\n",
        "\n",
        "INITIAL_ENV_START = 'S'\n",
        "INITIAL_ENV_GOAL = 'G'\n",
        "INITIAL_ENV_FLOOR = 'F'\n",
        "INITIAL_ENV_WALL = 'H'\n",
        "\n",
        "\n",
        "#logistic_env.env_gym.py\n",
        "LEFT = 0\n",
        "DOWN = 1\n",
        "RIGHT = 2\n",
        "UP = 3\n",
        "\n",
        "MAPS = {\n",
        "    \"4x4\": [\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"],\n",
        "    \"8x8\": [\n",
        "        \"SFFFFFFF\",\n",
        "        \"FFFFFFFF\",\n",
        "        \"FFFHFFFF\",\n",
        "        \"FFFFFHFF\",\n",
        "        \"FFFHFFFF\",\n",
        "        \"FHHFFFHF\",\n",
        "        \"FHFFHFHF\",\n",
        "        \"FFFHFFFG\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "IDX_LOG_STATE = 0\n",
        "IDX_LOG_Q_MAP = 1\n",
        "IDX_LOG_REWARD = 2\n",
        "IDX_LOG_ACTION = 3"
      ],
      "metadata": {
        "id": "TJB2_5KvLw0p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#csv save, load함수 + random_argmax 함수"
      ],
      "metadata": {
        "id": "rzmEzeYUL177"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#common.csv_.py\n",
        "import csv\n",
        "\n",
        "def save(path, str_):\n",
        "    with open(path, 'w', encoding='utf-8', newline='') as f:\n",
        "        wr = csv.writer(f)\n",
        "        for s in str_:\n",
        "            wr.writerow(s)\n",
        "\n",
        "def load(path):\n",
        "    with open(path, 'r', encoding='utf-8', newline='') as f:\n",
        "        rd = csv.reader(f)\n",
        "        data = []\n",
        "        for s in rd:\n",
        "            data.append([float(v) for v in s])\n",
        "    return data\n",
        "\n",
        "\n",
        "#common.func.py\n",
        "def random_argmax(vector):\n",
        "    # np.amax : 최댓값 반환\n",
        "    m = np.amax(vector)\n",
        "    #0이 아닌 최댓값 m을 반환\n",
        "    indices = np.nonzero(vector == m)[0]\n",
        "    # pr.choice : random choice\n",
        "    # indices에서 하나의 값을 랜덤으로 리턴\n",
        "    return pr.choice(indices)"
      ],
      "metadata": {
        "id": "X3JcQTFqL6N6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get_set_env 함수"
      ],
      "metadata": {
        "id": "hype9rZLMGdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#환경설정값 => input(집어와야하는아이템목록), 시작지점, 종료지점, 벽, 아이템 위치 설정\n",
        "def get_set_env(input_, p_start, p_end, p_wall, p_item):\n",
        "    #p_input = [(9,4)] + [(3,0),(0,5)] +[(9,4)]\n",
        "    #위의값은 C,J가 인풋으로 들어왔을 경우, (9,4) = 시작점, 도착점\n",
        "    p_input = [p_start] + [p_item[ch] for ch in input_] + [p_end]\n",
        "\n",
        "    p_start_end = []\n",
        "    for idx in range(len(p_input)-1):\n",
        "        p_start_end.append([p_input[idx], p_input[idx+1]])\n",
        "\n",
        "    #print(p_start_end)\n",
        "    # >>> [[(9, 4), (3, 0)], [(3, 0), (0, 5)], [(0, 5), (9, 4)]]\n",
        "\n",
        "    buf_wall = []\n",
        "    for p_s, p_e in p_start_end:\n",
        "        \n",
        "        #print(p_s, p_e)\n",
        "        #(9, 4) (3, 0)\n",
        "        #(3, 0) (0, 5)\n",
        "        #(0, 5) (9, 4)\n",
        "\n",
        "        buf_p = []\n",
        "        if p_s not in [p_start, p_end]:\n",
        "            buf_p.append(p_s)\n",
        "        if p_e not in [p_start, p_end]:\n",
        "            buf_p.append(p_e)\n",
        "\n",
        "        for p_ in p_item.values():\n",
        "            if (p_ == p_s) or (p_ == p_e):\n",
        "                continue\n",
        "            buf_p.append(p_)\n",
        "\n",
        "        # 자료가 리스트형일 떄\n",
        "        # append는 리스트에 리스트 형태의 자료를 그대로 넣어서 2차원으로 만들고\n",
        "        # extend는 기존 리스트에 값을 추가하여 결과적으로 1차원이 되도록 만든다\n",
        "        buf_p.extend(p_wall)\n",
        "        buf_wall.append(buf_p)\n",
        "    return zip(p_start_end, buf_wall)"
      ],
      "metadata": {
        "id": "d2_jaY-kL_jm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#메인함수1"
      ],
      "metadata": {
        "id": "Jao_9XHmMOCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ = [\"C\", \"J\"]\n",
        "\n",
        "# 환경설정값에 input, 시작점, 도착점, 벽, 아이템을 입력\n",
        "p_setting_env = list(get_set_env(input_, POINT_START, POINT_END, POINT_WALL, POINT_ITEM))\n",
        "\n",
        "id_env = ['LogisEnv-v1', 'LogisEnv-v2', 'LogisEnv-v3']\n",
        "path_map = ['./logistic_q_learning_map_1.csv', './logistic_q_learning_map_2.csv', './logistic_q_learning_map_3.csv']\n",
        "path = ['./logistic_q_learning_1_1.csv', './logistic_q_learning_1_2.csv', './logistic_q_learning_1_3.csv']\n",
        "\n",
        "list_q_map = []\n",
        "list_agent = []"
      ],
      "metadata": {
        "id": "VQehhwCcMJCF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create_map, print_env_map, generate_random_map 함수"
      ],
      "metadata": {
        "id": "g90vvrhbMaDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_map(num_row, num_col, start=None, goal=None, wall=None):\n",
        "    if start is None:\n",
        "        start = [0, 0]\n",
        "    if goal is None:\n",
        "        goal = [num_row, num_col]\n",
        "    map_ = [[INITIAL_ENV_FLOOR for _ in range(num_col)] for _ in range(num_row)]\n",
        "\n",
        "    #환경에서 벽을 만드는 부분\n",
        "    for idx_row, idx_col in wall:\n",
        "        map_[idx_row][idx_col] = INITIAL_ENV_WALL\n",
        "\n",
        "    #시작지점, 종료지점 지정\n",
        "    map_[start[0]][start[1]] = INITIAL_ENV_START\n",
        "    map_[goal[0]][goal[1]] = INITIAL_ENV_GOAL\n",
        "    return [\"\".join(x) for x in map_]\n",
        "\n",
        "#맵출력용 함수\n",
        "def print_env_map(env_map):\n",
        "    for map_ in env_map:\n",
        "        print(map_)\n",
        "\n",
        "\n",
        "def generate_random_map(size=8, p=0.8):\n",
        "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
        "    시작점에서 도착점까지의 길을 가지는 랜덤한 맵을 만든다\n",
        "    :param size: size of each side of the grid\n",
        "    param size : 각 그리드별 사이즈\n",
        "    :param p: probability that a tile is frozen\n",
        "    param p : 타일이 얼어있는지에 대한 가능성\n",
        "    \"\"\"\n",
        "    valid = False\n",
        "\n",
        "    # DFS to check that it's a valid path.\n",
        "    # DFS(깊이 우선 탐색)알고리즘으로 유효한 길인지 체크\n",
        "    def is_valid(res):\n",
        "        frontier, discovered = [], set()\n",
        "        frontier.append((0, 0))\n",
        "\n",
        "        # 반복문을 반복하면서 frontier에 좌표정보 추가\n",
        "        # discovered는 중복되지 않은 새로운 좌표만을 추가\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            #첫 r c 의 값은 0 0, 이후 이동방향에 따라 r,c의 값이 달라짐\n",
        "            if not (r, c) in discovered:\n",
        "                discovered.add((r, c))\n",
        "                #이동방향\n",
        "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == \"G\":\n",
        "                        return True\n",
        "                    if res[r_new][c_new] != \"H\":\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False\n",
        "\n",
        "    #S = start, G = Goal, F = Frozen, H = Hole\n",
        "    while not valid:\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice([\"F\", \"H\"], (size, size), p=[p, 1 - p])\n",
        "        res[0][0] = \"S\"\n",
        "        res[-1][-1] = \"G\"\n",
        "        valid = is_valid(res)\n",
        "    return [\"\".join(x) for x in res]"
      ],
      "metadata": {
        "id": "quWEs1TwMUmV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LogisticEnv 클래스"
      ],
      "metadata": {
        "id": "FI_2FiBXMmkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticEnv(Env):\n",
        "    \"\"\"\n",
        "    Logistic involves crossing a logistic map from Start(S) to Goal(G) without falling into any Holes(H) by walking over the Frozen(F) map.\n",
        "    로지스틱은 얼어있는 맵을 걸으며 어떤 홀에도 빠지지 않고 시작지점부터 도착지점까지 건너는 것입니다.\n",
        "    The agent may not always move in the intended direction due to the slippery nature of the logistic map.\n",
        "    에이전트는 항상 의도하지 않은 방향으로 움직일 수 있습니다.\n",
        "\n",
        "    ### Action Space\n",
        "    The agent takes a 1-element vector for actions.\n",
        "    The action space is `(dir)`, where `dir` decides direction to move in which can be:\n",
        "    - 0: LEFT\n",
        "    - 1: DOWN\n",
        "    - 2: RIGHT\n",
        "    - 3: UP\n",
        "\n",
        "    ### Observation Space\n",
        "    The observation is a value representing the agent's current position as current_row * nrows + current_col (where both the row and col start at 0).\n",
        "    observation은 현재 위치를 current_row * nrows + current_col 로 나타낸 값입니다(0,0에서 시작)\n",
        "    For example, the goal position in the 4x4 map can be calculated as follows: 3 * 4 + 3 = 15.\n",
        "    The number of possible observations is dependent on the size of the map.\n",
        "    가능한 observations의 수는 맵의 크기에 따라서 달라질 수 있습니다.\n",
        "    For example, the 4x4 map has 16 possible observations.\n",
        "    예를 들어, 4x4맵은 16개의 observations가 가능합니다.\n",
        "    ### Rewards\n",
        "    Reward schedule:\n",
        "    - Reach goal(G): +1\n",
        "    - Reach hole(H): 0\n",
        "    - Reach frozen(F): 0\n",
        "    ### Arguments\n",
        "    ```\n",
        "    gym.make('FrozenLake-v1', desc=None,map_name=\"4x4\", is_slippery=True)\n",
        "    ```\n",
        "    `desc`: Used to specify custom map for logistic map. For example,\n",
        "        desc=[\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"].\n",
        "    `map_name`: ID to use any of the preloaded maps.\n",
        "        \"4x4\":[\n",
        "            \"SFFF\",\n",
        "            \"FHFH\",\n",
        "            \"FFFH\",\n",
        "            \"HFFG\"\n",
        "            ]\n",
        "        \"8x8\": [\n",
        "            \"SFFFFFFF\",\n",
        "            \"FFFFFFFF\",\n",
        "            \"FFFHFFFF\",\n",
        "            \"FFFFFHFF\",\n",
        "            \"FFFHFFFF\",\n",
        "            \"FHHFFFHF\",\n",
        "            \"FHFFHFHF\",\n",
        "            \"FFFHFFFG\",\n",
        "        ]\n",
        "    `is_slippery`: True/False.\n",
        "                   If True will move in intended direction with probability of 1/3 else will move in either perpendicular direction with equal probability of 1/3 in both directions.\n",
        "                   만약 의도한 방향으로 움직일 가능성이 1/3이라면 1/3의 확률로 수직으로 이동할 것입니다.\n",
        "        For example, if action is left and is_slippery is True, then:\n",
        "        - P(move left)=1/3\n",
        "        - P(move up)=1/3\n",
        "        - P(move down)=1/3\n",
        "    ### Version History\n",
        "    * v1: Bug fixes to rewards\n",
        "    * v0: Initial versions release (1.0.0)\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\", \"ansi\", \"rgb_array\"], \"render_fps\": 4}\n",
        "\n",
        "    def __init__(self, map_name=\"4x4\", map_env=None, random_map=None, is_slippery=True):\n",
        "        # 인자에 따라 맵을 그대로 쓸 것인지, 랜덤맵을 사용할 것인지 정한다\n",
        "        # MAPS에는 \"4x4\" \"8x8\" 두가지가 위에 설정되어있다.\n",
        "        if map_env:\n",
        "            desc = map_env\n",
        "        elif random_map:\n",
        "            desc = generate_random_map(random_map[0], random_map[1])\n",
        "        else:\n",
        "            desc = MAPS[map_name]\n",
        "\n",
        "        self.desc = desc = np.asarray(desc, dtype=\"c\")\n",
        "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
        "        self.reward_range = (0, 1)\n",
        "\n",
        "        nA = 4\n",
        "        nS = nrow * ncol\n",
        "\n",
        "        self.initial_state_distrib = np.array(desc == b\"S\").astype(\"float64\").ravel()\n",
        "        self.initial_state_distrib /= self.initial_state_distrib.sum()\n",
        "\n",
        "        #{0: {0: [], 1: [], 2: [], 3: []},       1: {0: [], 1: [], 2: [], 3: []}, ..... 형태\n",
        "        self.P = {s: {a: [] for a in range(nA)} for s in range(nS)}\n",
        "\n",
        "        def to_s(row, col):\n",
        "            return row * ncol + col\n",
        "\n",
        "        def inc(row, col, a):\n",
        "\n",
        "            # 행동이 왼쪽일때 열을 하나뺀다\n",
        "            # -1이 나올때에 대한 대비\n",
        "            if a == LEFT:\n",
        "                col = max(col - 1, 0)\n",
        "\n",
        "            # 행동이 아래쪽일때 행을 하나 더하고, 행의 수를 하나 제거한다\n",
        "            # row가 row의 최대 길이보다 더 커지는 것을 방지\n",
        "            elif a == DOWN:\n",
        "                row = min(row + 1, nrow - 1)\n",
        "            elif a == RIGHT:\n",
        "                col = min(col + 1, ncol - 1)\n",
        "            elif a == UP:\n",
        "                row = max(row - 1, 0)\n",
        "            return (row, col)\n",
        "\n",
        "        def update_probability_matrix(row, col, action):\n",
        "            newrow, newcol = inc(row, col, action)\n",
        "            newstate = to_s(newrow, newcol)\n",
        "            newletter = desc[newrow, newcol]\n",
        "            done = bytes(newletter) in b\"GH\"\n",
        "            reward = 0\n",
        "            if newletter == b\"H\":\n",
        "                reward = -1\n",
        "            elif newletter == b\"G\":\n",
        "                reward = 1\n",
        "            # reward = float(newletter == b\"G\")\n",
        "            return newstate, reward, done\n",
        "\n",
        "        for row in range(nrow):\n",
        "            for col in range(ncol):\n",
        "                s = to_s(row, col)\n",
        "                for a in range(4):\n",
        "                    li = self.P[s][a]\n",
        "                    letter = desc[row, col]\n",
        "                    if letter in b\"GH\":\n",
        "                        li.append((1.0, s, 0, True))\n",
        "                    else:\n",
        "                        if is_slippery:\n",
        "                            for b in [(a - 1) % 4, a, (a + 1) % 4]:\n",
        "                                li.append(\n",
        "                                    (1.0 / 3.0, *update_probability_matrix(row, col, b))\n",
        "                                )\n",
        "                        else:\n",
        "                            li.append((1.0, *update_probability_matrix(row, col, a)))\n",
        "\n",
        "        self.observation_space = spaces.Discrete(nS)\n",
        "        self.action_space = spaces.Discrete(nA)\n",
        "\n",
        "        # pygame utils\n",
        "        self.window_size = (min(64 * ncol, 512), min(64 * nrow, 512))\n",
        "        self.window_surface = None\n",
        "        self.clock = None\n",
        "        self.hole_img = None\n",
        "        self.cracked_hole_img = None\n",
        "        self.ice_img = None\n",
        "        self.elf_images = None\n",
        "        self.goal_img = None\n",
        "        self.start_img = None\n",
        "\n",
        "\n",
        "    def step(self, a):\n",
        "        transitions = self.P[self.s][a]\n",
        "        i = categorical_sample([t[0] for t in transitions], self.np_random)\n",
        "        p, s, r, d = transitions[i]\n",
        "        self.s = s\n",
        "        self.lastaction = a\n",
        "        return (int(s), r, d, {\"prob\": p})\n",
        "\n",
        "    def reset(\n",
        "            self,\n",
        "            *,\n",
        "            seed: Optional[int] = None,\n",
        "            return_info: bool = False,\n",
        "            options: Optional[dict] = None):\n",
        "        super().reset(seed=seed)\n",
        "        self.s = categorical_sample(self.initial_state_distrib, self.np_random)\n",
        "        self.lastaction = None\n",
        "\n",
        "        if not return_info:\n",
        "            return int(self.s)\n",
        "        else:\n",
        "            return int(self.s), {\"prob\": 1}\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        desc = self.desc.tolist()\n",
        "        if mode == \"ansi\":\n",
        "            return self._render_text(desc)\n",
        "        else:\n",
        "            return self._render_gui(desc, mode)\n",
        "\n",
        "    def _render_gui(self, desc, mode):\n",
        "        if self.window_surface is None:\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            #타이틀바의 텍스트 설정\n",
        "            pygame.display.set_caption(\"Frozen Lake\")\n",
        "            if mode == \"human\":\n",
        "                self.window_surface = pygame.display.set_mode(self.window_size)\n",
        "            else:  # rgb_array\n",
        "                self.window_surface = pygame.Surface(self.window_size)\n",
        "        if self.clock is None:\n",
        "            self.clock = pygame.time.Clock()\n",
        "        if self.hole_img is None:\n",
        "            file_name = path.join(path.dirname(__file__), \"img/hole.png\")\n",
        "            self.hole_img = pygame.image.load(file_name)\n",
        "        if self.cracked_hole_img is None:\n",
        "            file_name = path.join(path.dirname(__file__), \"img/cracked_hole.png\")\n",
        "            self.cracked_hole_img = pygame.image.load(file_name)\n",
        "        if self.ice_img is None:\n",
        "            file_name = path.join(path.dirname(__file__), \"img/ice.png\")\n",
        "            self.ice_img = pygame.image.load(file_name)\n",
        "        if self.goal_img is None:\n",
        "            file_name = path.join(path.dirname(__file__), \"img/goal.png\")\n",
        "            self.goal_img = pygame.image.load(file_name)\n",
        "        if self.start_img is None:\n",
        "            file_name = path.join(path.dirname(__file__), \"img/stool.png\")\n",
        "            self.start_img = pygame.image.load(file_name)\n",
        "        if self.elf_images is None:\n",
        "            elfs = [\n",
        "                path.join(path.dirname(__file__), \"img/elf_left.png\"),\n",
        "                path.join(path.dirname(__file__), \"img/elf_down.png\"),\n",
        "                path.join(path.dirname(__file__), \"img/elf_right.png\"),\n",
        "                path.join(path.dirname(__file__), \"img/elf_up.png\"),\n",
        "            ]\n",
        "            self.elf_images = [pygame.image.load(f_name) for f_name in elfs]\n",
        "\n",
        "        #surface생성, furface = 2d 객체를 의미\n",
        "        board = pygame.Surface(self.window_size, flags=SRCALPHA)\n",
        "        cell_width = self.window_size[0] // self.ncol\n",
        "        cell_height = self.window_size[1] // self.nrow\n",
        "        smaller_cell_scale = 0.6\n",
        "        small_cell_w = smaller_cell_scale * cell_width\n",
        "        small_cell_h = smaller_cell_scale * cell_height\n",
        "\n",
        "        # prepare images\n",
        "        last_action = self.lastaction if self.lastaction is not None else 1\n",
        "        elf_img = self.elf_images[last_action]\n",
        "        elf_scale = min(\n",
        "            small_cell_w / elf_img.get_width(),\n",
        "            small_cell_h / elf_img.get_height(),\n",
        "        )\n",
        "        elf_dims = (\n",
        "            elf_img.get_width() * elf_scale,\n",
        "            elf_img.get_height() * elf_scale,\n",
        "        )\n",
        "        elf_img = pygame.transform.scale(elf_img, elf_dims)\n",
        "        hole_img = pygame.transform.scale(self.hole_img, (cell_width, cell_height))\n",
        "        cracked_hole_img = pygame.transform.scale(\n",
        "            self.cracked_hole_img, (cell_width, cell_height)\n",
        "        )\n",
        "        ice_img = pygame.transform.scale(self.ice_img, (cell_width, cell_height))\n",
        "        goal_img = pygame.transform.scale(self.goal_img, (cell_width, cell_height))\n",
        "        start_img = pygame.transform.scale(self.start_img, (small_cell_w, small_cell_h))\n",
        "\n",
        "        for y in range(self.nrow):\n",
        "            for x in range(self.ncol):\n",
        "                rect = (x * cell_width, y * cell_height, cell_width, cell_height)\n",
        "                if desc[y][x] == b\"H\":\n",
        "                    self.window_surface.blit(hole_img, (rect[0], rect[1]))\n",
        "                elif desc[y][x] == b\"G\":\n",
        "                    self.window_surface.blit(ice_img, (rect[0], rect[1]))\n",
        "                    goal_rect = self._center_small_rect(rect, goal_img.get_size())\n",
        "                    self.window_surface.blit(goal_img, goal_rect)\n",
        "                elif desc[y][x] == b\"S\":\n",
        "                    self.window_surface.blit(ice_img, (rect[0], rect[1]))\n",
        "                    stool_rect = self._center_small_rect(rect, start_img.get_size())\n",
        "                    self.window_surface.blit(start_img, stool_rect)\n",
        "                else:\n",
        "                    self.window_surface.blit(ice_img, (rect[0], rect[1]))\n",
        "\n",
        "                pygame.draw.rect(board, (180, 200, 230), rect, 1)\n",
        "\n",
        "        # paint the elf\n",
        "        bot_row, bot_col = self.s // self.ncol, self.s % self.ncol\n",
        "        cell_rect = (\n",
        "            bot_col * cell_width,\n",
        "            bot_row * cell_height,\n",
        "            cell_width,\n",
        "            cell_height,\n",
        "        )\n",
        "        if desc[bot_row][bot_col] == b\"H\":\n",
        "            self.window_surface.blit(cracked_hole_img, (cell_rect[0], cell_rect[1]))\n",
        "        else:\n",
        "            elf_rect = self._center_small_rect(cell_rect, elf_img.get_size())\n",
        "            self.window_surface.blit(elf_img, elf_rect)\n",
        "\n",
        "        self.window_surface.blit(board, board.get_rect())\n",
        "        if mode == \"human\":\n",
        "            # pygame 이벤트 핸들러 내부 처리\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "            self.clock.tick(self.metadata[\"render_fps\"])\n",
        "        else:  # rgb_array\n",
        "            return np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(self.window_surface)), axes=(1, 0, 2)\n",
        "            )\n",
        "\n",
        "    @staticmethod\n",
        "    def _center_small_rect(big_rect, small_dims):\n",
        "        offset_w = (big_rect[2] - small_dims[0]) / 2\n",
        "        offset_h = (big_rect[3] - small_dims[1]) / 2\n",
        "        return (\n",
        "            big_rect[0] + offset_w,\n",
        "            big_rect[1] + offset_h,\n",
        "        )\n",
        "\n",
        "    def _render_text(self, desc):\n",
        "        outfile = StringIO()\n",
        "\n",
        "        row, col = self.s // self.ncol, self.s % self.ncol\n",
        "        desc = [[c.decode(\"utf-8\") for c in line] for line in desc]\n",
        "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
        "        if self.lastaction is not None:\n",
        "            outfile.write(f\"  ({['Left', 'Down', 'Right', 'Up'][self.lastaction]})\\n\")\n",
        "        else:\n",
        "            outfile.write(\"\\n\")\n",
        "        outfile.write(\"\\n\".join(\"\".join(line) for line in desc) + \"\\n\")\n",
        "\n",
        "        with closing(outfile):\n",
        "            return outfile.getvalue()"
      ],
      "metadata": {
        "id": "UbD6Wj-MMi-n"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create_env 함수"
      ],
      "metadata": {
        "id": "bkF2c3JmM0oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_env(id_, manual=False, map_name='4x4', map_env=None, random_map=None, is_slippery=False):\n",
        "    setting = None\n",
        "    if manual:\n",
        "        setting = {'map_env': map_env, 'is_slippery': is_slippery}\n",
        "    elif random_map:\n",
        "        setting = {'random_map': (random_map[0], random_map[1]), 'is_slippery': is_slippery}\n",
        "    else:\n",
        "        setting = {'map_name': map_name, 'is_slippery': is_slippery}\n",
        "\n",
        "    register(\n",
        "        id=id_,\n",
        "        #LogisticEnv 클래스를 의미함\n",
        "        entry_point=LogisticEnv,\n",
        "        kwargs=setting\n",
        "    )\n",
        "    env = gym.make(id_)\n",
        "    return env"
      ],
      "metadata": {
        "id": "vhzC2nKdMw6R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QLearning 클래스"
      ],
      "metadata": {
        "id": "BSRY_JyvM7Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearning:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        # self.__log_epi = [[state_step, q_map_step, reward_step, act_step], ...]\n",
        "        self.__log_epi = []\n",
        "\n",
        "    # __get_log_item의 항목 참고\n",
        "    def get_log_state(self):\n",
        "        return self.__get_log_item(IDX_LOG_STATE)\n",
        "\n",
        "    def get_log_q_map(self): \n",
        "        return self.__get_log_item(IDX_LOG_Q_MAP)\n",
        "\n",
        "    def get_log_reward(self):\n",
        "        return self.__get_log_item(IDX_LOG_REWARD)\n",
        "\n",
        "    def get_log_action(self):\n",
        "        return self.__get_log_item(IDX_LOG_ACTION)\n",
        "\n",
        "    def save_q_map(self, path, q_map):\n",
        "        return save(path, q_map)\n",
        "\n",
        "    def load_q_map(self, path):\n",
        "        return load(path)\n",
        "\n",
        "    def run(self, num_episodes, q_map=None, early_stopping=False):\n",
        "        del self.__log_epi\n",
        "        self.__log_epi = []\n",
        "        if early_stopping:\n",
        "            early_stopping.clear()\n",
        "\n",
        "        if q_map:\n",
        "            q_map = np.array(q_map)\n",
        "\n",
        "       # q_map이 지정되지 않은 경우, observation_space와 action_space 로 numpy.zeros의 행렬 만들기\n",
        "        else:\n",
        "            q_map = np.zeros([self.env.observation_space.n, self.env.action_space.n])\n",
        "\n",
        "        num_progress = 0\n",
        "        for i in range(num_episodes):\n",
        "            # __run_episodes(self, q_map, idx=0, greedy=False, noise=False, learning_rate=0, discount=1):\n",
        "            # self.__run_episodes(q_map)\n",
        "            self.__run_episodes(q_map, noise=True, discount=0.9)\n",
        "\n",
        "            #진행상황 나타낼 떄 사용\n",
        "            num_ = int((i / num_episodes) * 100)\n",
        "            if num_progress != num_:\n",
        "                print(f'progress = {num_} %')\n",
        "                num_progress = num_\n",
        "\n",
        "            # 진행상황과 언제 early_stopping이 되었는지 표시할 때 사용한다.\n",
        "            if early_stopping:\n",
        "                if early_stopping.check_stopping(self.__log_epi[-1][IDX_LOG_ACTION]):\n",
        "                    print(f'progress = {num_} %  --> {i}/{num_episodes} Early Stopping')\n",
        "                    break\n",
        "        sum_reward_by_epi = self.__get_log_sum_reward()\n",
        "        return q_map, sum_reward_by_epi\n",
        "\n",
        "    def __run_episodes(self, q_map, idx=0, greedy=False, noise=False, learning_rate=0, discount=1.):\n",
        "        log_step = [[] for _ in range(4)]\n",
        "        # 초기 state 설정 (Start)\n",
        "        state = self.env.reset()\n",
        "\n",
        "        done = False\n",
        "        while not done:\n",
        "            act = None\n",
        "\n",
        "            # e-greedy\n",
        "            if greedy:\n",
        "                e = 1. / ((idx // 1000) + 1)\n",
        "                if np.random.rand(1) < e:\n",
        "                    act = self.env.action_space.sample()\n",
        "                else:\n",
        "                    act = random_argmax(q_map[state, :])\n",
        "            # noise\n",
        "            elif noise:\n",
        "                act = np.argmax(q_map[state, :] + np.random.randn(1, self.env.action_space.n) / (idx + 1))\n",
        "            else:\n",
        "                act = random_argmax(q_map[state, :])\n",
        "            new_state, reward, done, _ = self.env.step(act)\n",
        "\n",
        "            if state != new_state:\n",
        "                #러닝레이트가 존재하면 if, 존재하지 않을 경우 else를 실행한다 - 러닝레이트를 넣을 때와 넣지 않을때 식이 다르기때문\n",
        "                if learning_rate > 0:\n",
        "                    q_map[state, act] = (1 - learning_rate) * q_map[state, act] + learning_rate * (\n",
        "                                reward + discount * np.max(q_map[new_state, :]))\n",
        "                else:\n",
        "                    q_map[state, act] = reward + discount * np.max(q_map[new_state, :])\n",
        "            # log\n",
        "            for idx, val in enumerate([state, 0, reward, act]):\n",
        "                log_step[idx].append(val)\n",
        "            # update state\n",
        "            state = new_state\n",
        "        self.__log_epi.append(log_step)\n",
        "        return True\n",
        "\n",
        "    def __get_log_sum_reward(self):\n",
        "        return [sum(reward_epi) for reward_epi in self.get_log_reward()]\n",
        "\n",
        "    # idx를 입력으로 받는다.(위의 경우에는 get_log_state부터 get_log_q_map..... 을 0, 1, 2, 3 순서로 받는다.)\n",
        "    # __log_epi는 92번째 줄에서(현재줄로부터 7줄 위) log_step의 값을 받는다.\n",
        "    # log_step은 [[], [], [], []]의 형태를 가지고, val은 [state, 0, reward, act] 의 값을 받아서 생성된다.\n",
        "    # 최종적으로 for 문에 들어가는 __log_epi는 [[state, 0, reward, act], [state, 0, reward, act], [state, 0, reward, act], [state, 0, reward, act]] 의 형태를 가진다\n",
        "    # log_epi[idx] 형태는 예를 들어 log_epi[0]일 경우 state, log_epi[1]일 경우 q_map을 의미하게 된다.\n",
        "    def __get_log_item(self, idx):\n",
        "        log_item = []\n",
        "        for log_epi in self.__log_epi:\n",
        "            log_item.append(log_epi[idx])\n",
        "        return log_item"
      ],
      "metadata": {
        "id": "uQnGfnIZM40V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# earlystopping 클래스"
      ],
      "metadata": {
        "id": "dWsdswheNEqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, ratio=100):\n",
        "        self.stack = []\n",
        "        self.patience = patience\n",
        "        self.ratio = ratio\n",
        "\n",
        "    def clear(self):\n",
        "        del self.stack\n",
        "        self.stack = []\n",
        "\n",
        "    # stack에 값을 추가하고 num을 check_ratio에서 세었던 num의 값으로 초기화한다\n",
        "    # 위에서 입력한 비율보다 크거나 같을 경우 True, 아니면 False를 반환한다\n",
        "    def check_stopping(self, value):\n",
        "        self.__add_stack(value)\n",
        "        num = self.__check_ratio()\n",
        "        if ((num // self.patience)*100) >= self.ratio:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    #stack의 길이가 patience보다 클 경우 제일 앞 stack 제거\n",
        "    def __add_stack(self, value):\n",
        "        if len(self.stack) > self.patience:\n",
        "            del self.stack[0]\n",
        "        self.stack.append(value)\n",
        "\n",
        "    # stack의 마지막값을 stand로 지정하고 num = 0으로 설정\n",
        "    # stack의 마지막 값과 스택의 요소가 같으면 num에 +1을 더한다\n",
        "    # 비율을 정하기 이전에 num을 세는 함수\n",
        "    # stack은 1, 2, 3.... 과 같이 되어있을 수도 있지만 3, 3, 3, 3 .... 3 의 형식으로 되어있을 수도 있음\n",
        "    # 앞의 경우는 num이 하나만 오를 수도 있지만, 뒤의 경우에는 num의 숫자가 계속 오름\n",
        "    # early stoping의 조건을 충족시키기 위하여 사용\n",
        "    def __check_ratio(self):\n",
        "        stand = self.stack[-1]\n",
        "        num = 0\n",
        "        for val in self.stack:\n",
        "            if stand == val:\n",
        "                num += 1\n",
        "        return num"
      ],
      "metadata": {
        "id": "e_IB0pG3NA0e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#메인함수2"
      ],
      "metadata": {
        "id": "Z1mjtATvNKrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p_start_end[0]에는 시작 좌표, p_start_end[1]에는 목표 좌표가 찍혀있음\n",
        "for idx, (p_start_end, p_wall) in enumerate(p_setting_env):\n",
        "    map_env = create_map(NUM_ROW, NUM_COL, start=p_start_end[0], goal=p_start_end[1], wall=p_wall)\n",
        "    print_env_map(map_env)\n",
        "    save(path_map[idx], map_env)\n",
        "\n",
        "    env = create_env(id_=id_env[idx], manual=True, map_env=map_env)\n",
        "\n",
        "    agent = QLearning(env)\n",
        "    q_map, sum_reward_by_epi = agent.run(NUM_EPISODES, early_stopping=EarlyStopping())\n",
        "    agent.save_q_map(path[idx], q_map.tolist())\n",
        "    list_q_map.append(q_map)\n",
        "    list_agent.append(agent)\n",
        "\n",
        "\n",
        "path_ = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE-GkdQ8NI_g",
        "outputId": "4231991f-272c-4ad8-a28d-59c47b4b258b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HHHHHHHHH\n",
            "FFFFFFFFF\n",
            "HFFFFFFFH\n",
            "GFHFHFHFH\n",
            "HFHFHFHFH\n",
            "HFHFHFHFH\n",
            "FFHFHFHFF\n",
            "FFFFFFFFF\n",
            "FFFFFFFFF\n",
            "HHHHSHHHH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment LogisEnv-v1\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {id}\")\n",
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:506: UserWarning: \u001b[33mWARN: The environment LogisEnv-v1 is out of date. You should consider upgrading to version `v3` with the environment ID `LogisEnv-v3`.\u001b[0m\n",
            "  f\"The environment {path} is out of date. You should consider \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress = 1 %\n",
            "progress = 2 %\n",
            "progress = 3 %\n",
            "progress = 4 %\n",
            "progress = 5 %\n",
            "progress = 6 %\n",
            "progress = 7 %\n",
            "progress = 8 %\n",
            "progress = 9 %\n",
            "progress = 10 %\n",
            "progress = 11 %\n",
            "progress = 12 %\n",
            "progress = 13 %\n",
            "progress = 14 %\n",
            "progress = 15 %\n",
            "progress = 16 %\n",
            "progress = 17 %\n",
            "progress = 18 %\n",
            "progress = 19 %\n",
            "progress = 20 %\n",
            "progress = 21 %\n",
            "progress = 22 %\n",
            "progress = 23 %\n",
            "progress = 24 %\n",
            "progress = 25 %\n",
            "progress = 26 %\n",
            "progress = 27 %\n",
            "progress = 28 %\n",
            "progress = 29 %\n",
            "progress = 30 %\n",
            "progress = 31 %\n",
            "progress = 32 %\n",
            "progress = 33 %\n",
            "progress = 34 %\n",
            "progress = 35 %\n",
            "progress = 36 %\n",
            "progress = 37 %\n",
            "progress = 38 %\n",
            "progress = 39 %\n",
            "progress = 40 %\n",
            "progress = 41 %\n",
            "progress = 42 %\n",
            "progress = 43 %\n",
            "progress = 44 %\n",
            "progress = 45 %\n",
            "progress = 46 %\n",
            "progress = 47 %\n",
            "progress = 48 %\n",
            "progress = 49 %\n",
            "progress = 50 %\n",
            "progress = 51 %\n",
            "progress = 52 %\n",
            "progress = 53 %\n",
            "progress = 54 %\n",
            "progress = 55 %\n",
            "progress = 56 %\n",
            "progress = 57 %\n",
            "progress = 58 %\n",
            "progress = 59 %\n",
            "progress = 60 %\n",
            "progress = 61 %\n",
            "progress = 62 %\n",
            "progress = 63 %\n",
            "progress = 64 %\n",
            "progress = 65 %\n",
            "progress = 66 %\n",
            "progress = 67 %\n",
            "progress = 68 %\n",
            "progress = 69 %\n",
            "progress = 70 %\n",
            "progress = 71 %\n",
            "progress = 72 %\n",
            "progress = 73 %\n",
            "progress = 74 %\n",
            "progress = 75 %\n",
            "progress = 76 %\n",
            "progress = 77 %\n",
            "progress = 78 %\n",
            "progress = 79 %\n",
            "progress = 80 %\n",
            "progress = 81 %\n",
            "progress = 82 %\n",
            "progress = 83 %\n",
            "progress = 84 %\n",
            "progress = 85 %\n",
            "progress = 86 %\n",
            "progress = 87 %\n",
            "progress = 88 %\n",
            "progress = 89 %\n",
            "progress = 90 %\n",
            "progress = 91 %\n",
            "progress = 92 %\n",
            "progress = 93 %\n",
            "progress = 94 %\n",
            "progress = 95 %\n",
            "progress = 96 %\n",
            "progress = 97 %\n",
            "progress = 98 %\n",
            "progress = 99 %\n",
            "HHHHHGHHH\n",
            "FFFFFFFFF\n",
            "HFFFFFFFH\n",
            "SFHFHFHFH\n",
            "HFHFHFHFH\n",
            "HFHFHFHFH\n",
            "FFHFHFHFF\n",
            "FFFFFFFFF\n",
            "FFFFFFFFF\n",
            "HHHHFHHHH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment LogisEnv-v2\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {id}\")\n",
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:506: UserWarning: \u001b[33mWARN: The environment LogisEnv-v2 is out of date. You should consider upgrading to version `v3` with the environment ID `LogisEnv-v3`.\u001b[0m\n",
            "  f\"The environment {path} is out of date. You should consider \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress = 1 %\n",
            "progress = 2 %\n",
            "progress = 3 %\n",
            "progress = 4 %\n",
            "progress = 5 %\n",
            "progress = 6 %\n",
            "progress = 7 %\n",
            "progress = 8 %\n",
            "progress = 9 %\n",
            "progress = 10 %\n",
            "progress = 11 %\n",
            "progress = 12 %\n",
            "progress = 13 %\n",
            "progress = 14 %\n",
            "progress = 15 %\n",
            "progress = 16 %\n",
            "progress = 17 %\n",
            "progress = 18 %\n",
            "progress = 19 %\n",
            "progress = 20 %\n",
            "progress = 21 %\n",
            "progress = 22 %\n",
            "progress = 23 %\n",
            "progress = 24 %\n",
            "progress = 25 %\n",
            "progress = 26 %\n",
            "progress = 27 %\n",
            "progress = 28 %\n",
            "progress = 29 %\n",
            "progress = 30 %\n",
            "progress = 31 %\n",
            "progress = 32 %\n",
            "progress = 33 %\n",
            "progress = 34 %\n",
            "progress = 35 %\n",
            "progress = 36 %\n",
            "progress = 37 %\n",
            "progress = 38 %\n",
            "progress = 39 %\n",
            "progress = 40 %\n",
            "progress = 41 %\n",
            "progress = 42 %\n",
            "progress = 43 %\n",
            "progress = 44 %\n",
            "progress = 45 %\n",
            "progress = 46 %\n",
            "progress = 47 %\n",
            "progress = 48 %\n",
            "progress = 49 %\n",
            "progress = 50 %\n",
            "progress = 51 %\n",
            "progress = 52 %\n",
            "progress = 53 %\n",
            "progress = 54 %\n",
            "progress = 55 %\n",
            "progress = 56 %\n",
            "progress = 57 %\n",
            "progress = 58 %\n",
            "progress = 59 %\n",
            "progress = 60 %\n",
            "progress = 61 %\n",
            "progress = 62 %\n",
            "progress = 63 %\n",
            "progress = 64 %\n",
            "progress = 65 %\n",
            "progress = 66 %\n",
            "progress = 67 %\n",
            "progress = 68 %\n",
            "progress = 69 %\n",
            "progress = 70 %\n",
            "progress = 71 %\n",
            "progress = 72 %\n",
            "progress = 73 %\n",
            "progress = 74 %\n",
            "progress = 75 %\n",
            "progress = 76 %\n",
            "progress = 77 %\n",
            "progress = 78 %\n",
            "progress = 79 %\n",
            "progress = 80 %\n",
            "progress = 81 %\n",
            "progress = 82 %\n",
            "progress = 83 %\n",
            "progress = 84 %\n",
            "progress = 85 %\n",
            "progress = 86 %\n",
            "progress = 87 %\n",
            "progress = 88 %\n",
            "progress = 89 %\n",
            "progress = 90 %\n",
            "progress = 91 %\n",
            "progress = 92 %\n",
            "progress = 93 %\n",
            "progress = 94 %\n",
            "progress = 95 %\n",
            "progress = 96 %\n",
            "progress = 97 %\n",
            "progress = 98 %\n",
            "progress = 99 %\n",
            "HHHHHSHHH\n",
            "FFFFFFFFF\n",
            "HFFFFFFFH\n",
            "HFHFHFHFH\n",
            "HFHFHFHFH\n",
            "HFHFHFHFH\n",
            "FFHFHFHFF\n",
            "FFFFFFFFF\n",
            "FFFFFFFFF\n",
            "HHHHGHHHH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment LogisEnv-v3\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {id}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress = 1 %\n",
            "progress = 2 %\n",
            "progress = 3 %\n",
            "progress = 4 %\n",
            "progress = 5 %\n",
            "progress = 6 %\n",
            "progress = 7 %\n",
            "progress = 8 %\n",
            "progress = 9 %\n",
            "progress = 10 %\n",
            "progress = 11 %\n",
            "progress = 12 %\n",
            "progress = 13 %\n",
            "progress = 14 %\n",
            "progress = 15 %\n",
            "progress = 16 %\n",
            "progress = 17 %\n",
            "progress = 18 %\n",
            "progress = 19 %\n",
            "progress = 20 %\n",
            "progress = 21 %\n",
            "progress = 22 %\n",
            "progress = 23 %\n",
            "progress = 24 %\n",
            "progress = 25 %\n",
            "progress = 26 %\n",
            "progress = 27 %\n",
            "progress = 28 %\n",
            "progress = 29 %\n",
            "progress = 30 %\n",
            "progress = 31 %\n",
            "progress = 32 %\n",
            "progress = 33 %\n",
            "progress = 34 %\n",
            "progress = 35 %\n",
            "progress = 36 %\n",
            "progress = 37 %\n",
            "progress = 38 %\n",
            "progress = 39 %\n",
            "progress = 40 %\n",
            "progress = 41 %\n",
            "progress = 42 %\n",
            "progress = 43 %\n",
            "progress = 44 %\n",
            "progress = 45 %\n",
            "progress = 46 %\n",
            "progress = 47 %\n",
            "progress = 48 %\n",
            "progress = 49 %\n",
            "progress = 50 %\n",
            "progress = 51 %\n",
            "progress = 52 %\n",
            "progress = 53 %\n",
            "progress = 54 %\n",
            "progress = 55 %\n",
            "progress = 56 %\n",
            "progress = 57 %\n",
            "progress = 58 %\n",
            "progress = 59 %\n",
            "progress = 60 %\n",
            "progress = 61 %\n",
            "progress = 62 %\n",
            "progress = 63 %\n",
            "progress = 64 %\n",
            "progress = 65 %\n",
            "progress = 66 %\n",
            "progress = 67 %\n",
            "progress = 68 %\n",
            "progress = 69 %\n",
            "progress = 70 %\n",
            "progress = 71 %\n",
            "progress = 72 %\n",
            "progress = 73 %\n",
            "progress = 74 %\n",
            "progress = 75 %\n",
            "progress = 76 %\n",
            "progress = 77 %\n",
            "progress = 78 %\n",
            "progress = 79 %\n",
            "progress = 80 %\n",
            "progress = 81 %\n",
            "progress = 82 %\n",
            "progress = 83 %\n",
            "progress = 84 %\n",
            "progress = 85 %\n",
            "progress = 86 %\n",
            "progress = 87 %\n",
            "progress = 88 %\n",
            "progress = 89 %\n",
            "progress = 90 %\n",
            "progress = 91 %\n",
            "progress = 92 %\n",
            "progress = 93 %\n",
            "progress = 94 %\n",
            "progress = 95 %\n",
            "progress = 96 %\n",
            "progress = 97 %\n",
            "progress = 98 %\n",
            "progress = 99 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get_idx_direct, get_move_p, get_path, print_str_direct 함수"
      ],
      "metadata": {
        "id": "RNmv57TnNndV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx_direct(q_map):\n",
        "    cnt = 0\n",
        "    map_idx_direct = []\n",
        "    while cnt < len(q_map)-1:\n",
        "        for _ in range(9):\n",
        "            #q_map에서 가장 큰 값을 val_max로 초기화한다\n",
        "            val_max = q_map[cnt].max()\n",
        "            # 가장 큰 값이 없으면 None을 추가하고\n",
        "            if val_max == 0:\n",
        "                map_idx_direct.append(None)\n",
        "            # 있다면 q_map[cnt]에서 val_max의 index값을 idx로 초기화하고 map_idx_direct에 추가한다 \n",
        "            # IDX_ACTION = [IDX_ACTION_LEFT, IDX_ACTION_DOWN, IDX_ACTION_RIGHT, IDX_ACTION_UP]\n",
        "            else:\n",
        "                idx = list(q_map[cnt]).index(val_max)\n",
        "                if idx in IDX_ACTION:\n",
        "                    map_idx_direct.append(idx)\n",
        "            cnt += 1\n",
        "    return map_idx_direct\n",
        "\n",
        "# p_state = [row, col], move = list(0~3사이의 값들이 있음)\n",
        "# 이동 방향에 따라 row, col 업데이트\n",
        "def get_move_p(p_state, move, max_row, max_col):\n",
        "    row = p_state[0]\n",
        "    col = p_state[1]\n",
        "\n",
        "    if move == IDX_ACTION_UP:\n",
        "        row -= 1\n",
        "    elif move == IDX_ACTION_DOWN:\n",
        "        row += 1\n",
        "    elif move == IDX_ACTION_LEFT:\n",
        "        col -= 1\n",
        "    elif move == IDX_ACTION_RIGHT:\n",
        "        col += 1\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    # row =  1번. 만약 row가 0보다 작으면 0\n",
        "    #        2번. row>=max_row라면 max_row-1\n",
        "    #        3번. 1번, 2번이 모두 아닐경우 row\n",
        "    row = 0 if row < 0 else max_row-1 if row >= max_row else row\n",
        "    col = 0 if col < 0 else max_col-1 if col >= max_col else col\n",
        "    return [row, col]\n",
        "\n",
        "#p_start, p_end = p_start_end[0], p_start_end[1]\n",
        "def get_path(map_idx_direct, p_start, p_end, max_row, max_col):\n",
        "    row = p_start[0]\n",
        "    col = p_start[1]\n",
        "\n",
        "    path_ = [[row, col]]\n",
        "    # map_idx_direct = 0,1,2,3 의 방향을 가진다. 이동경로이므로 여러개의 값이 리스트 형태로 들어있음\n",
        "    for _ in range(len(map_idx_direct)):\n",
        "\n",
        "        # 2차원 배열처럼 사용\n",
        "        # map_idx_direct는 1차원 리스트\n",
        "        # row, col은 원래 2차원이므로 (row * max_col) + col을 할 경우 2차원배열을 1차원 배열로 바꾸었을 때 값이 출력될 수 있음\n",
        "        # 예를들어 1차원 배열이 a = [0 1 2 3 4 5 6 7 8]이고, \n",
        "        # 2차원 배열이\n",
        "        # 0 1 2\n",
        "        # 3 4 5\n",
        "        # 6 7 8\n",
        "        # 일 때 숫자 5를 뽑고 싶으면 2차원배열에서는 (1,2)로 지정이 된다.\n",
        "        # 즉 (row * max_col) = (1 * 2) = 2가 되고 현재 col인 2를 더하면 a[2+2]가 되어서 a[4]의 값인 5를 출력할 수 있다.\n",
        "        idx_direct = map_idx_direct[(row*max_col)+col]\n",
        "\n",
        "        # [row,col] = p_state\n",
        "        # idx_direct는 하나의 방향이 나옴(0~3의 값)\n",
        "        # get_move_p 로 (row,col)의 값을 업데이트 한다\n",
        "        p_next = get_move_p([row, col], idx_direct, max_row, max_col)\n",
        "\n",
        "        # p_next가 존재하지 않거나 이미 지정된 값(row, col)과 p_next가 같다면 반복문을 빠져나간다.\n",
        "        if (p_next is False) or (p_next == [row, col]):\n",
        "            break\n",
        "        row = p_next[0]\n",
        "        col = p_next[1]\n",
        "        path_.append(p_next)\n",
        "        if p_next == p_end:\n",
        "            break\n",
        "    return path_\n",
        "\n",
        "# NUM_COL = 9로 설정되어있음\n",
        "# idx_direct = map_idx_direct = 1차원 리스트\n",
        "def print_str_direct(idx_direct, num_col):\n",
        "    char_direct = []\n",
        "    cnt = 0\n",
        "    while cnt < len(idx_direct)-1:\n",
        "        txt = ''\n",
        "        buf = []\n",
        "        for idx in range(num_col):\n",
        "            char_ = None\n",
        "            # IDX_ACTION = [IDX_ACTION_LEFT, IDX_ACTION_DOWN, IDX_ACTION_RIGHT, IDX_ACTION_UP]\n",
        "            # IDX_ACTION_LEFT = 0\n",
        "            # IDX_ACTION_DOWN = 1\n",
        "            # IDX_ACTION_RIGHT = 2\n",
        "            # IDX_ACTION_UP = 3\n",
        "            if idx_direct[cnt] in IDX_ACTION:\n",
        "                # INITIAL_ACTION = [INITIAL_ACTION_LEFT, INITIAL_ACTION_DOWN, INITIAL_ACTION_RIGHT, INITIAL_ACTION_UP]\n",
        "                # INITIAL_ACTION_UP = 'U'\n",
        "                # INITIAL_ACTION_DOWN = 'D'\n",
        "                # INITIAL_ACTION_RIGHT = 'R'\n",
        "                # INITIAL_ACTION_LEFT = 'L'\n",
        "\n",
        "                char_ = INITIAL_ACTION[idx_direct[cnt]]\n",
        "            else:\n",
        "                char_ = ' '\n",
        "            txt += char_\n",
        "            buf.append(char_)\n",
        "\n",
        "            # 출력시 칸 구분할 때 \"ㅣ\" 사용\n",
        "            if idx < num_col-1:\n",
        "                txt += ' | '\n",
        "            cnt += 1\n",
        "        print(txt)\n",
        "        char_direct.append(buf)\n",
        "    return char_direct"
      ],
      "metadata": {
        "id": "F7Tsr4wfNRVx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#메인함수3"
      ],
      "metadata": {
        "id": "1z4AGLMtNwcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (p_start_end, p_wall) in enumerate(p_setting_env):\n",
        "    q_map = list_q_map[idx]\n",
        "    map_idx_direct = get_idx_direct(q_map)\n",
        "    buf_path = get_path(map_idx_direct, p_start_end[0], p_start_end[1], NUM_ROW, NUM_COL)\n",
        "    path_.append(buf_path)\n",
        "    print_str_direct(map_idx_direct, NUM_COL)"
      ],
      "metadata": {
        "id": "FFXj07jnNvgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e11a027-fb5f-4abc-92b3-8a21a32ff3fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  |   |   |   |   |   |   |   |  \n",
            "R | D | L | L | L | L | L | L | L\n",
            "  | D | L | L | L | L | L | L |  \n",
            "  | L |   | U |   | U |   | U |  \n",
            "  | U |   | U |   | U |   | U |  \n",
            "  | U |   | U |   | U |   | U |  \n",
            "R | U |   | D |   | D |   | D | L\n",
            "R | U | L | L | L | L | L | L | L\n",
            "R | U | L | L | L | L | L | L | L\n",
            "  |   |   |   | U |   |   |   |  \n",
            "  |   |   |   |   |   |   |   |  \n",
            "R | R | R | R | R | U | L | L | L\n",
            "  | R | R | R | R | U | L | L |  \n",
            "R | U |   | U |   | U |   | U |  \n",
            "  | U |   | U |   | U |   | U |  \n",
            "  | U |   | U |   | U |   | U |  \n",
            "R | U |   | U |   | U |   | U | L\n",
            "R | R | R | R | R | U | L | L | L\n",
            "R | R | R | R | R | U | L | L | L\n",
            "  |   |   |   | U |   |   |   |  \n",
            "  |   |   |   |   | D |   |   |  \n",
            "R | D | D | D | L | D | L | L | L\n",
            "  | D | R | D | L | D | L | L |  \n",
            "  | D |   | D |   | D |   | D |  \n",
            "  | D |   | D |   | D |   | D |  \n",
            "  | D |   | D |   | D |   | D |  \n",
            "D | D |   | D |   | D |   | D | L\n",
            "D | D | D | D | D | L | L | L | L\n",
            "R | R | R | R | D | L | L | L | L\n",
            "  |   |   |   |   |   |   |   |  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YpxKoYFoNyiO"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}