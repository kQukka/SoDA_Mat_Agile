{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"q_learning_exploration_rev1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNibeRng8lDDK5MnGh8AMYs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YZFZswsdDlH9"},"outputs":[],"source":["import gym\n","import numpy as np\n","from gym.envs.registration import register\n","import random as pr"]},{"cell_type":"code","source":["NUM_EPISODES = 2000\n","POINT_WALL = [[1, 1], [1, 3], [2, 3], [3, 0]]\n","POINT_GOAL = [[3, 3]]\n"],"metadata":{"id":"qPakHphhEpoR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rargmax(vector):\n","    # np,amax = array의 최댓값 반환\n","    m = np.amax(vector)\n","    indices = np.nonzero(vector == m)[0]\n","    # 0이 아닌값 중에 m과 같은 값이 있으면\n","    # pr.choice(indices)\n","    # indices 중 random으로 choice\n","    return pr.choice(indices)\n","    "],"metadata":{"id":"WfWRHyBfFXJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_episodes_ori(env, q_value):\n","    done = False\n","    rAll = 0\n","    # 초기 state로 설정\n","    state = env.reset()\n","\n","    buf_q = []\n","    buf_act = []\n","    while not done:\n","        action = rargmax(q_value[state, :])\n","\n","        # done : learning 종료 (목적지 도착)\n","        new_state, reward, done, _ = env.step(action)\n","\n","        q_value[state, action] = reward + np.max(q_value[new_state, :])\n","\n","        buf_q.append(list(q_value[state]))\n","        if done:\n","            buf_q.append(list(q_value[new_state]))\n","        buf_act.append(action)\n","        rAll += reward\n","        state = new_state\n","    return buf_q, rAll, buf_act\n","    "],"metadata":{"id":"jpgS16MZEprA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_episodes_explo(env, q_value, e, i):\n","    dis = .9\n","\n","    done = False\n","    rAll = 0\n","    # 초기 state로 설정\n","    state = env.reset()\n","\n","    buf_q = []\n","    buf_act = []\n","    while not done:\n","        # e-greedy\n","        # action = None\n","        # if np.random.rand(1) < e:\n","        #     action = env.action_space.sample()\n","        # else:\n","        #     action = rargmax(q_value[state, :])\n","\n","        # noise\n","        action = np.argmax(q_value[state, :]+np.random.randn(1, env.action_space.n)/(i+1))\n","\n","        # done : learning 종료 (목적지 도착)\n","        new_state, reward, done, _ = env.step(action)\n","\n","        # if state != new_state:\n","        #     q_value[state, action] = reward + dis * np.max(q_value[new_state, :])\n","\n","        q_value[state, action] = reward + dis * np.max(q_value[new_state, :])\n","\n","        buf_q.append(list(q_value[state]))\n","        if done:\n","            buf_q.append(list(q_value[new_state]))\n","        buf_act.append(action)\n","        rAll += reward\n","        state = new_state\n","    return buf_q, rAll, buf_act\n","    "],"metadata":{"id":"PtNawv7dEptq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_q_learning(env, num_episodes, explo = False):\n","    # Q-value table 생성\n","    q_value = np.zeros([env.observation_space.n, env.action_space.n])\n","\n","    # reword 저장\n","    log_reword = []\n","    log_q_by_step = []\n","    log_action = []\n","    log_q_map = []\n","    log_e = []\n","    for i in range(num_episodes):\n","        e = 1. / ((i // 1000) + 1)\n","        log_e.append(e)\n","\n","        buf_q = None\n","        rAll = None\n","        buf_act = None\n","        if explo:\n","            buf_q, rAll, buf_act = run_episodes_explo(env, q_value, e, i)\n","        else:\n","            buf_q, rAll, buf_act = run_episodes_ori(env, q_value)\n","\n","        log_action.append(buf_act)\n","        log_q_by_step.append(buf_q)\n","        log_reword.append(rAll)\n","        log_q_map.append(q_value.copy())\n","    return q_value, log_reword, log_q_map, log_action, log_q_by_step\n"],"metadata":{"id":"-iNha6EYEpwe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4x4 환경"],"metadata":{"id":"KMVeQ8OlapwU"}},{"cell_type":"code","source":["# entry_point : gym.envs 환경 불러오기\n","register(\n","    id='LakeEnv-v1',\n","    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","    kwargs={'map_name': '4x4', 'is_slippery': False}\n",")\n","env = gym.make('LakeEnv-v1')\n"],"metadata":{"id":"CDcK0aCqEpzR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## q_learning 기본"],"metadata":{"id":"FidW5QwmZPnf"}},{"cell_type":"code","source":["result_ = []\n","cnt = 100\n","for _ in range(cnt):\n","    q_value, log_reword, log_q_map, log_action, log_q_by_step = run_q_learning(env, NUM_EPISODES)\n","    res = sum(log_reword) / NUM_EPISODES\n","    result_.append(res)\n","\n","print('Max success rate : ' + str(max(result_)))\n","print('Avg success rate : ' + str(sum(result_)/cnt))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-I5tVskJwHs","executionInfo":{"status":"ok","timestamp":1651150844190,"user_tz":-540,"elapsed":55105,"user":{"displayName":"Jung Hyun Lee","userId":"01154420143394984910"}},"outputId":"7ecdbad3-1545-4137-f939-88df220e724a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max success rate : 0.995\n","Avg success rate : 0.9379599999999999\n"]}]},{"cell_type":"markdown","source":["## q_learning exploration (noise, discounted reward)"],"metadata":{"id":"4DL_aeqsZYg6"}},{"cell_type":"code","source":["result_ = []\n","cnt = 100\n","for _ in range(cnt):\n","    q_value, log_reword, log_q_map, log_action, log_q_by_step = run_q_learning(env, NUM_EPISODES, True)\n","    res = sum(log_reword) / NUM_EPISODES\n","    result_.append(res)\n","\n","print('Max success rate : ' + str(max(result_)))\n","print('Avg success rate : ' + str(sum(result_)/cnt))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RC0P2uu5Ep2v","executionInfo":{"status":"ok","timestamp":1651150886221,"user_tz":-540,"elapsed":42035,"user":{"displayName":"Jung Hyun Lee","userId":"01154420143394984910"}},"outputId":"6797e698-eb63-4277-8d6c-f96f91b12b28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max success rate : 0.989\n","Avg success rate : 0.9339700000000002\n"]}]},{"cell_type":"markdown","source":["- 특별한 차이를 보이지 않음\n","- 최단경로를 찾아가는 알고리즘 적용이기 때문에 최단경로를 적게 가지고 있는 환경에서의 테스트와 최단경로 추출에 대한 성공률 측정이 필요함"],"metadata":{"id":"m6kPWd1kzIZH"}},{"cell_type":"markdown","source":["# 8x8 환경"],"metadata":{"id":"TIpGZplUahm5"}},{"cell_type":"code","source":["# entry_point : gym.envs 환경 불러오기\n","register(\n","    id='LakeEnv-v2',\n","    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","    kwargs={'map_name': '8x8', 'is_slippery': False}\n",")\n","env = gym.make('LakeEnv-v2')\n"],"metadata":{"id":"-noK5gq4Ep5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## q_learning 기본"],"metadata":{"id":"5m5kn7O7ahdD"}},{"cell_type":"code","source":["result_ = []\n","cnt = 100\n","for _ in range(cnt):\n","    q_value, log_reword, log_q_map, log_action, log_q_by_step = run_q_learning(env, NUM_EPISODES)\n","    res = sum(log_reword) / NUM_EPISODES\n","    result_.append(res)\n","\n","print('Max success rate : ' + str(max(result_)))\n","print('Avg success rate : ' + str(sum(result_)/cnt))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USaiul29Ep9E","executionInfo":{"status":"ok","timestamp":1651151075443,"user_tz":-540,"elapsed":189238,"user":{"displayName":"Jung Hyun Lee","userId":"01154420143394984910"}},"outputId":"2b462f04-2294-46a9-cd20-5ad8e0328602"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max success rate : 0.9185\n","Avg success rate : 0.5808650000000002\n"]}]},{"cell_type":"markdown","source":["## q_learning exploration (noise, Discounted reward)"],"metadata":{"id":"y7uvzWlhaXXc"}},{"cell_type":"code","source":["result_ = []\n","cnt = 100\n","for _ in range(cnt):\n","    q_value, log_reword, log_q_map, log_action, log_q_by_step = run_q_learning(env, NUM_EPISODES, True)\n","    res = sum(log_reword) / NUM_EPISODES\n","    result_.append(res)\n","\n","print('Max success rate : ' + str(max(result_)))\n","print('Avg success rate : ' + str(sum(result_)/cnt))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBLWiZ5EEqAB","executionInfo":{"status":"ok","timestamp":1651151226636,"user_tz":-540,"elapsed":151200,"user":{"displayName":"Jung Hyun Lee","userId":"01154420143394984910"}},"outputId":"86dea21c-46a2-4069-b4f0-4bb918f808d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max success rate : 0.9445\n","Avg success rate : 0.5575750000000003\n"]}]},{"cell_type":"markdown","source":["- 특별한 차이를 보이지 않음\n","- 최단경로 추출에 대한 성공률 측정이 필요함"],"metadata":{"id":"BgzWKUo2aw64"}}]}