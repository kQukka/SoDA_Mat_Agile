{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_03.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q-learning 최적 경로 출력\n",
        "- q_learning_02 버전의 최적 경로 출력 문제 보완"
      ],
      "metadata": {
        "id": "0hZRIilu7vzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gym\n",
        "from gym.envs.registration import register"
      ],
      "metadata": {
        "id": "aexofKvhCUzT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#환경 변수\n",
        "IDX_ACTION_UP = 0\n",
        "IDX_ACTION_DOWN = 1\n",
        "IDX_ACTION_RIGHT = 2\n",
        "IDX_ACTION_LEFT = 3\n",
        "\n",
        "STR_ACTION_UP = 'U'\n",
        "STR_ACTION_DOWN = 'D'\n",
        "STR_ACTION_RIGHT = 'R'\n",
        "STR_ACTION_LEFT = 'L'\n",
        "\n",
        "ENV_ID = 'FrozenLake-v3'\n",
        "NUM_EPISODES = 2000\n",
        "\n",
        "GOAL_STATE = 15\n",
        "\n",
        "# 환경 등록\n",
        "def get_env_register(env_id):\n",
        "    env_dict = gym.envs.registry.env_specs.copy()\n",
        " \n",
        "    for env in env_dict:\n",
        "        if env_id in env:\n",
        "            print('Remove {} from registry'.format(env))\n",
        "            del gym.envs.registry.env_specs[env]   \n",
        "\n",
        "    register(\n",
        "        id=env_id,\n",
        "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
        "        kwargs={'map_name': '4x4',\n",
        "                'is_slippery': False}\n",
        "    )\n",
        "    \n",
        "    env = gym.make(env_id)\n",
        "\n",
        "    return env\n",
        "\n",
        "# Q-table 시각화\n",
        "def print_str_direct(q_value):\n",
        "    cnt = 0\n",
        "    while cnt < len(q_value):\n",
        "        txt = ''\n",
        "        for _ in range(4):\n",
        "            # q-value가 실수인 경우 보완\n",
        "            q = ''.join([str(int(round(e, 0))) for e in q_value[cnt]])\n",
        "            if q == '1000':\n",
        "                txt += STR_ACTION_UP\n",
        "            elif q == '0100':\n",
        "                txt += STR_ACTION_DOWN\n",
        "            elif q == '0010':\n",
        "                txt += STR_ACTION_RIGHT\n",
        "            elif q == '0001':\n",
        "                txt += STR_ACTION_LEFT\n",
        "            else:\n",
        "                txt += ' '\n",
        "            txt += ' | '\n",
        "            cnt += 1\n",
        "        print(txt)    \n",
        "\n",
        "def print_q_table(q_value):\n",
        "    print('-'*50)\n",
        "    print(\"Final Q-Table Values\")\n",
        "    print('-'*50)\n",
        "    print('state | U   D   R   L')\n",
        "    print(q_value)\n"
      ],
      "metadata": {
        "id": "trsAC8ZiCWUz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-learning algorithm with Decaying E-greedy\n",
        "def do_qlearning_decay_egreedy(env, num_episodes):\n",
        "    q_value = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "    rList = []\n",
        "    cntList = [] \n",
        "    dis = 0.99 \n",
        "\n",
        "    min_act = env.observation_space.n * env.action_space.n\n",
        "    optimal_q_value = []\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        state = env.reset()         \n",
        "        done = False\n",
        "        action_cnt = 0\n",
        "        rAll = 0 \n",
        "\n",
        "        e = 1./((i // 100) + 1)\n",
        "\n",
        "        b_success = False\n",
        "\n",
        "        while not done:       \n",
        "            if np.random.uniform(0, 1) < e:\n",
        "                action = env.action_space.sample()\n",
        "            else : \n",
        "                action = np.argmax(q_value[state, :])\n",
        "\n",
        "            new_state, reward, done, _ = env.step(action)\n",
        "            \n",
        "            q_value[state, action] = reward + dis * np.max(q_value[new_state, :]) \n",
        "            \n",
        "            rAll += reward\n",
        "            action_cnt +=1\n",
        "           \n",
        "            if new_state == GOAL_STATE:\n",
        "                b_success = True\n",
        "\n",
        "            state = new_state\n",
        "\n",
        "        rList.append(rAll)\n",
        "        cntList.append(action_cnt)\n",
        "\n",
        "        # 최단거리로 Goal간경우 q_value를 optimal value로 설정\n",
        "        if b_success and action_cnt < min_act:            \n",
        "            min_act = action_cnt\n",
        "            optimal_q_value = q_value\n",
        "           \n",
        "    return q_value, rList, cntList, optimal_q_value, min_act"
      ],
      "metadata": {
        "id": "Mrkz1e5G_tug"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = get_env_register(ENV_ID)\n",
        "q_value, rList, cntList, optimal_q_value, min_act = do_qlearning_decay_egreedy(env, NUM_EPISODES)\n",
        "print('**** Success rate:{} min_act:{} '.format((sum(rList) / NUM_EPISODES), min_act))\n",
        "print(\"Success average action : \" + str(sum(cntList) / NUM_EPISODES)) # 평균 액션 횟수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qv8-CjC_4hH",
        "outputId": "24073408-0b96-4dfc-f2ab-ec39e990a0f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remove FrozenLake-v3 from registry\n",
            "**** Success rate:0.818 min_act:6 \n",
            "Success average action : 6.361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_q_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMPpAzGb_903",
        "outputId": "2a53fff8-7f4f-4baf-c862-1d821edb5c90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.94148015, 0.95099005, 0.95099005, 0.94148015],\n",
              "       [0.94148015, 0.        , 0.96059601, 0.95099005],\n",
              "       [0.95099005, 0.970299  , 0.95099005, 0.96059601],\n",
              "       [0.96059601, 0.        , 0.95099005, 0.95099005],\n",
              "       [0.95099005, 0.96059601, 0.        , 0.94148015],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.9801    , 0.        , 0.96059601],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.96059601, 0.        , 0.970299  , 0.95099005],\n",
              "       [0.96059601, 0.9801    , 0.9801    , 0.        ],\n",
              "       [0.970299  , 0.99      , 0.        , 0.970299  ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.9801    , 0.99      , 0.970299  ],\n",
              "       [0.9801    , 0.99      , 1.        , 0.9801    ],\n",
              "       [0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimal_path(optimal_q_value):\n",
        "    list_optimal_step = []\n",
        "    optimal_step = 0\n",
        "    optimal_path = []\n",
        "\n",
        "    #q-value중 max값을 1로 변경하기\n",
        "    qvalue_table = np.zeros([optimal_q_value.shape[0], optimal_q_value.shape[1]])\n",
        "\n",
        "    for state, q_value in enumerate(optimal_q_value):\n",
        "        q_max = np.amax(q_value)  # q_value array의 최댓값 반환\n",
        "        indices = np.nonzero(q_value == q_max)[0]\n",
        "        qvalue_table[state, indices[0]] = 1\n",
        "        state += 1\n",
        "\n",
        "    #print(qvalue_table)\n",
        "\n",
        "    for state, q_value in enumerate(qvalue_table):\n",
        "        index = q_value.argmax()\n",
        "\n",
        "        if optimal_step == state : # 최단 경로 위에 있는 state에 대해 최적경로step을 지정한다.\n",
        "            list_optimal_step.append(optimal_step)\n",
        "\n",
        "            if optimal_step == GOAL_STATE:\n",
        "                q_value = [0,0,0,0]\n",
        "            else:   \n",
        "                if index == IDX_ACTION_UP :\n",
        "                    optimal_step -= 4\n",
        "                elif index == IDX_ACTION_DOWN :\n",
        "                    optimal_step += 4\n",
        "                elif index == IDX_ACTION_RIGHT :\n",
        "                    optimal_step += 1\n",
        "                elif index == IDX_ACTION_RIGHT :\n",
        "                    optimal_step -= 1\n",
        "                else: \n",
        "                    pass\n",
        "        else:\n",
        "            q_value = [0,0,0,0]\n",
        "        \n",
        "        optimal_path.append(list(map(int,q_value)))\n",
        "\n",
        "    #print(list_optimal_step)\n",
        "    #print(optimal_path)\n",
        "\n",
        "    if optimal_step != GOAL_STATE:\n",
        "        print(\"Agent can't find optimal path.\")\n",
        "    return optimal_path"
      ],
      "metadata": {
        "id": "z8jEngZcAKAY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최종 route 출력\n",
        "optimal_weight = get_optimal_path(optimal_q_value)\n",
        "print_str_direct(optimal_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9-1oI1hAzOw",
        "outputId": "d326d899-97a0-428b-dc79-7350518def49"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D |   |   |   | \n",
            "D |   |   |   | \n",
            "R | D |   |   | \n",
            "  | R | R |   | \n"
          ]
        }
      ]
    }
  ]
}