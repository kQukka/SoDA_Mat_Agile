{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_network_tf2_path.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Network 최적 경로 출력\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YcEH3OhAS0b_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcoZl_KgPx8a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(x):\n",
        "    return np.identity(16)[x:x+1].astype(np.float32)"
      ],
      "metadata": {
        "id": "WUH_8s7jP01t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#환경 변수\n",
        "IDX_ACTION_UP = 0\n",
        "IDX_ACTION_DOWN = 1\n",
        "IDX_ACTION_RIGHT = 2\n",
        "IDX_ACTION_LEFT = 3\n",
        "\n",
        "STR_ACTION_UP = 'U'\n",
        "STR_ACTION_DOWN = 'D'\n",
        "STR_ACTION_RIGHT = 'R'\n",
        "STR_ACTION_LEFT = 'L'\n",
        "\n",
        "GOAL_STATE = 15\n",
        "\n",
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "# Set Q-learning parameters\n",
        "num_episodes = 5000\n",
        "learning_rate = 0.1\n",
        "dis = .99\n",
        "\n",
        "# Input and output size based on the Env\n",
        "input_size = env.observation_space.n\n",
        "output_size = env.action_space.n\n",
        "\n",
        "# weight\n",
        "W = tf.Variable(tf.random.uniform([input_size, output_size], 0, 0.01), dtype=tf.float32)\n",
        "# optimizer \n",
        "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "R3G51aUuP2qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-table 시각화\n",
        "def print_str_direct(q_value):\n",
        "    cnt = 0\n",
        "    while cnt < len(q_value):\n",
        "        txt = ''\n",
        "        for _ in range(4):\n",
        "            # q-value가 실수인 경우 보완\n",
        "            q = ''.join([str(int(round(e, 0))) for e in q_value[cnt]])\n",
        "            if q == '1000':\n",
        "                txt += STR_ACTION_UP\n",
        "            elif q == '0100':\n",
        "                txt += STR_ACTION_DOWN\n",
        "            elif q == '0010':\n",
        "                txt += STR_ACTION_RIGHT\n",
        "            elif q == '0001':\n",
        "                txt += STR_ACTION_LEFT\n",
        "            else:\n",
        "                txt += ' '\n",
        "            txt += ' | '\n",
        "            cnt += 1\n",
        "        print(txt)    "
      ],
      "metadata": {
        "id": "bllG-yfKQJ5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "rList = []\n",
        "\n",
        "min_act = env.observation_space.n * env.action_space.n\n",
        "optimal_W = []\n",
        "optimal_q_value = []\n",
        "\n",
        "for i in range(num_episodes):\n",
        "    b_success = False   # goal에 도착한경우\n",
        "    action_cnt = 0      # action 횟수 설정\n",
        "\n",
        "    state = env.reset()\n",
        "    rAll = 0\n",
        "    done = False\n",
        "    local_loss = []\n",
        "    e = 1. / ((i / 50) + 10)\n",
        "    \n",
        "    while not done:\n",
        "        q_value = tf.matmul(one_hot(state), W) \n",
        "        q_value = np.array(q_value.numpy())\n",
        "\n",
        "        if np.random.rand(1) < e:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(q_value)\n",
        "\n",
        "        state_next, reward, done, _ = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            q_value[0, action] = reward\n",
        "        else:\n",
        "            q_score_next = tf.matmul(one_hot(state_next), W)  \n",
        "            q_value[0, action] = reward + dis * np.max(q_score_next) \n",
        "        loss = lambda: tf.reduce_sum(input_tensor=tf.square(q_value - tf.matmul(one_hot(state), W)))\n",
        "\n",
        "        optimizer.minimize(loss, var_list=W)\n",
        "        \n",
        "        rAll += reward\n",
        "        action_cnt +=1\n",
        "        state = state_next\n",
        "\n",
        "        if state_next == GOAL_STATE:\n",
        "            b_success = True\n",
        "\n",
        "    rList.append(rAll)\n",
        "\n",
        "    # 최단거리로 Goal간경우 q_value를 optimal value로 설정\n",
        "    if b_success and action_cnt < min_act:            \n",
        "        min_act = action_cnt\n",
        "        optimal_W = W"
      ],
      "metadata": {
        "id": "WN3ZHwKhP2nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{(time.time() - start_time)} seconds')\n",
        "print(\"Success rate: \" + str(sum(rList) / num_episodes))\n",
        "plt.bar(range(len(rList)), rList, color='b', alpha=0.4)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "0cgsmy6PVGk6",
        "outputId": "8f628f79-d23d-414e-f2cb-2745dfcb5d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "656.9769451618195 seconds\n",
            "Success rate: 0.553\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 최적 경로 출력"
      ],
      "metadata": {
        "id": "JD_i2eyJRIyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimal_path(optimal_q_value):\n",
        "    list_optimal_step = []\n",
        "    optimal_step = 0\n",
        "    optimal_path = []\n",
        "\n",
        "    #q-value중 max값을 1로 변경\n",
        "    qvalue_table = np.zeros([optimal_q_value.shape[0], optimal_q_value.shape[1]])\n",
        "\n",
        "    for state, q_value in enumerate(optimal_q_value):\n",
        "        q_max = np.amax(q_value)  # q_value array의 최댓값 반환\n",
        "        indices = np.nonzero(q_value == q_max)[0]\n",
        "        qvalue_table[state, indices[0]] = 1\n",
        "        state += 1\n",
        "\n",
        "    #print(qvalue_table)\n",
        "\n",
        "    for state, q_value in enumerate(qvalue_table):\n",
        "        index = q_value.argmax()\n",
        "\n",
        "        if optimal_step == state : # 최단 경로 위에 있는 state에 대해 최적경로step을 지정한다.\n",
        "            list_optimal_step.append(optimal_step)\n",
        "\n",
        "            if optimal_step == GOAL_STATE:\n",
        "                q_value = [0,0,0,0]\n",
        "            else:   \n",
        "                if index == IDX_ACTION_UP :\n",
        "                    optimal_step -= 4\n",
        "                elif index == IDX_ACTION_DOWN :\n",
        "                    optimal_step += 4\n",
        "                elif index == IDX_ACTION_RIGHT :\n",
        "                    optimal_step += 1\n",
        "                elif index == IDX_ACTION_LEFT :\n",
        "                    optimal_step -= 1\n",
        "                else: \n",
        "                    pass\n",
        "        else:\n",
        "            q_value = [0,0,0,0]\n",
        "        \n",
        "        optimal_path.append(list(map(int,q_value)))\n",
        "\n",
        "    #print(list_optimal_step)\n",
        "    #print(optimal_path)\n",
        "\n",
        "    if optimal_step != GOAL_STATE:\n",
        "        print(\"Agent can't find optimal path.\")\n",
        "    return optimal_path"
      ],
      "metadata": {
        "id": "c_hVaHS5RH4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8hV_F9_e4_M",
        "outputId": "f42e71a1-9381-4201-c3fc-38d786e133de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(16, 4) dtype=float32, numpy=\n",
              "array([[4.0580216e-01, 3.2390481e-01, 2.9369134e-01, 3.2419205e-01],\n",
              "       [1.8227494e-01, 2.6723081e-01, 2.5923607e-01, 3.2316986e-01],\n",
              "       [2.4382497e-01, 2.5963655e-01, 2.4983278e-01, 2.8213221e-01],\n",
              "       [2.2618996e-01, 1.9795075e-01, 1.5135767e-01, 2.6163682e-01],\n",
              "       [4.4303235e-01, 3.0679798e-01, 1.9065730e-01, 1.8682507e-01],\n",
              "       [3.3919907e-03, 3.9888239e-03, 1.8386745e-03, 9.8750340e-03],\n",
              "       [3.9356995e-01, 1.6061597e-01, 8.8367045e-02, 6.5831997e-02],\n",
              "       [5.0370526e-03, 8.2054362e-03, 6.0477243e-03, 1.1861157e-03],\n",
              "       [3.2245511e-01, 3.5307741e-01, 3.3513162e-01, 5.0553268e-01],\n",
              "       [3.1363946e-01, 5.8030903e-01, 3.4519148e-01, 4.0205607e-01],\n",
              "       [5.6709683e-01, 3.2785010e-01, 1.4580201e-01, 2.5536975e-01],\n",
              "       [4.0074098e-03, 9.9304384e-03, 2.9873252e-03, 9.3891686e-03],\n",
              "       [7.3160644e-04, 1.4047384e-04, 5.7265353e-03, 6.9081243e-03],\n",
              "       [3.4429336e-01, 4.3062094e-01, 6.6502041e-01, 4.3188396e-01],\n",
              "       [6.2336278e-01, 5.2469933e-01, 8.6487758e-01, 5.9978318e-01],\n",
              "       [6.4767059e-03, 8.0108640e-07, 1.3021457e-03, 9.7023398e-03]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#최종 route 출력\n",
        "optimal_path = get_optimal_path(optimal_W)\n",
        "print_str_direct(optimal_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XX-WShPVXjk",
        "outputId": "66d38c9e-c4cb-44c6-d8a7-73544cf82c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent can't find optimal path.\n",
            "U |   |   |   | \n",
            "  |   |   |   | \n",
            "  |   |   |   | \n",
            "  |   |   |   | \n"
          ]
        }
      ]
    }
  ]
}